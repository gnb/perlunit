PerlUnit TODO
=============

Here's our roadmap.  It should give you an idea of what is planned,
and in some cases when it's planned for and/or who's going to do it.
Only update this file on the main branch!

See also doc/consensus.txt.

* Before release 1.0

None of these are big jobs, but Adam thinks they should all be done
before 1.0 if we want the framework to gain respect and widespread
usage; after all, many people will check out PerlUnit for the first
time when they hear 1.0 being announced, and first impressions count
for a lot.

** $Error::Depth bug

TestRunner.pm isn't reporting the source of failures properly, e.g.

There was 1 failure:
1) /nfs-home/adams/lib/perl5/site_perl/5.6.0/Test/Unit/Assertion/CodeRef.pm:20
expected 'foo', got 'bar'

Seems to happen for all the %assert_subs tests only.

** Rename Test::Unit::HarnessUnit and Test::Unit::UnitHarness

Not sure what to yet, but we want to get these big API changes out of
the way before we bump the version number.

** Get working build on 5.7.2

Piers is doing this imminently.

* Nice to have before 1.0

Some of these could be left until after 1.0.  Adam thinks it makes
sense to do the first two before the release, however.

** Tidy up copyrights, credits, and licensing

We currently have copyrights, licenses, and out of date author
attributions in pretty much every file in the distribution.  This is
messy, and a pain to maintain.  It would be good to move all the
copyrights and credits into one or two files (COPYING or LICENSE or
AUTHORS, say), and then to change the licensing/credit bits and pieces
in all the other files into something which refers to that one file,
and also states that none of the files should be distributed
separately, only as an entire package, thereby preventing the
copyright-containing file from being disassociated from the others.

** Rethink how the tests are split up between the t/*.t.

Currently we have t/all_tests.t, which is clearly a misnomer, and we
have some tests for the assertion code being run from that rather than
from t/assert.t.

** Test::Unit::Loader working with whole directories.

** Test filtering

Piers suggested the beautiful idea of using Attribute::Handlers so you
could do things like:

  sub test_something : todo {...}
  sub test_something : skip_if(<condition>) {...}
  sub test_something : skip {...}

Adam needs this for work ASAP, and will probably implement it very soon.
There is already a primitive filtering mechanism in place which is
controlled by the filter() and filter_method() methods.

* After 1.0

No harm done if they end up being done before 1.0 though, of course.

** Tests to add

*** PerlUnit selftests

**** die errors that look like variable names  [mca]

A test that fails with an error like

  die '$lotsofdollars';

and make sure it gets wrapped into an ExceptionError

**** doing the right OOP thing in constructors and isa() checks

Possibly a test that overrides the 'isa' method so Piers' fix to my
patch

  (back to using $exception->isa(C) instead of UNIVERSAL::isa($exception,C))

can be exercised.

Also Adam has patched some of the PerlUnit constructors to allow
passing a classname instead of being invoked as a method.

**** check for broken Error.pm overloading of exceptions [as]

Older Error.pms don't do boolean overload, so

  eval { ... };
  if ($@) {
    ...
  }

could break.  We should check for that.

*** Generic tests for users to include

Matthew wrote some. Whether anyone else wants them remains to be seen.

The potentially useful ones:

**** test_SubsAllNeedTests

Checks all subs in a module are tested. Take the code and put it
somewhere else.

**** test_PodChecker

Look the sourcecode up in %INC and run it through the Pod::Checker
(which spits out stuff to STDOUT regardless).

**** test_HaveWarnings

Check $^W .. a bit cheeky. I was actually after a check for
strictness, after forgetting to use it in some module I broke off, but
this is either tricky or impossible.

[Impossible I believe. That's kind of the point of lexical scope after all
   -- pdc]

*** Test coverage tests

There was a big thread on this but it's someone else's turn to write
about that. 8-)  -- mca

Current thinking is to keep test-coverage tests away from the executed
tests, mainly so you can have a script which draws a pretty chart of
how well your code is tested. Adam has some code for this.

** output STDOUT only if error

Tie STDOUT via IO::Scalar to capture output from calls to print() etc.
within test cases, and only print output if there's an error.

* Personal TODO lists

Moved here from doc/consensus.txt.

** Matthew

*** Consider removing examples/tester* (uses old Test::SuiteWrapper)

*** Make Debian package

*** Find a neat way to run unit-tested programs without the suite

It's convenient for medium sized projects to stick the test subs in
the classes they test, but then you have a run-time dependence on perlunit.

**** Local Variables:
**** mode: outline
**** End:

